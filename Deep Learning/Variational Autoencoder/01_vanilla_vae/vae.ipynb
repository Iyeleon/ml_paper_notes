{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4779144b-2f82-47ba-8d49-b5fb8cd00045",
   "metadata": {},
   "source": [
    "# Understanding Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf33a9-5082-4371-a8dc-c612a628020c",
   "metadata": {},
   "source": [
    "The notebook documents my explorations in undertsanding how to train a directed probabilistic models and deep latent variable models using variational inference. Here, I explore different aspects of the paper *Autoencoding Variational Bayes*, and the book *An Introduction to Variational AutoEncoders* both written/coauthored by ***Diederik P. Kingma and Max Welling***. \n",
    "<br><br>\n",
    "My readings and notes on both materials are documented in this[note](here) and my [blog](blog_link). These spaces are where I write for personal recollection, and I hope any one who comes across them finds them useful for quick intuitive understanding of this topic.\n",
    "\n",
    "This notebook is in two sections\n",
    "1) An exploration and understanding of the concepts and objective of the Variational AutoEncoder.\n",
    "   - Mathematically and visually look into understanding the model parameters, prior and posterior distributions\n",
    "   - Explore ELBO - Evidence Lower Bound\n",
    "   - Reparametrization Trick\n",
    "   - Optimization methods for updating parameters of the model.  <br><br>\n",
    "  \n",
    "2) Understand how to train a Variational Autoencoder using two examples\n",
    "   - Bernoulli VAE with a gaussian prior.\n",
    "   - Gaussian VAE with a gaussian prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee3e28-b3bb-4f74-aa81-e48bf662762a",
   "metadata": {},
   "source": [
    "# 00 - Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a8e35-0f41-4425-8932-240452890f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ccfe7-89f1-420b-9923-08c3ce268460",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8154aef-ec36-41b7-b3f9-2c107a89c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(arr, num_rows = 2, num_cols = 6, title = \"Sample Dataset\", cmap = None, shuffle = True):\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize = (num_cols * 2, num_rows * 2))\n",
    "    if shuffle:\n",
    "        seed = np.random.randint(200)\n",
    "        np.random.shuffle(arr)\n",
    "    selection = np.random.choice(np.arange(0, len(arr)), num_rows * num_cols, replace = False)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(len(ax)):\n",
    "        ax[i].imshow(arr[i], cmap = cmap)\n",
    "        ax[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a3e05-3232-494d-ab02-f46e6030ce21",
   "metadata": {},
   "source": [
    "# 02 - Bernoulli VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c098049-716b-4ecf-afab-46750b60ee34",
   "metadata": {},
   "source": [
    "## 2A - Bernoulli VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672656b9-47f1-46da-9612-749a17522dc0",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55c694-df12-47f6-93a6-0bffcf36b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for bernoulli data\n",
    "mnist_train, mnist_val = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db03108-2815-4975-a2bb-71bac34d7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set:', mnist_train[0].shape[0])\n",
    "print('Validation set:', mnist_val[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9ae22-6bd0-41fa-8b81-cfb92b1cde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(data):\n",
    "    data = np.expand_dims(data, axis = -1)\n",
    "    data = data / 255\n",
    "    data = np.where(data < 0.2, 0, 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa133ff-3f60-4cd9-bb13-90bc590b050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale images from 0 to 1\n",
    "mnist_train_images = preprocess_mnist(mnist_train[0])\n",
    "mnist_val_images = preprocess_mnist(mnist_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8a7b7-c0d3-4349-b77a-3632da57320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088d362-3cf8-4fdd-a8e3-56501e1735d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_y = (\n",
    "    {'reconstruction' : mnist_train_images},\n",
    "    {'latent' : [np.zeros(mnist_train_images.shape[0]), np.zeros(mnist_train_images.shape[0])]}, \n",
    ")\n",
    "mnist_val_y = (\n",
    "    {'reconstruction' : mnist_val_images}, \n",
    "    {'latent' : [np.zeros(mnist_val_images.shape[0]), np.zeros(mnist_val_images.shape[0])]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dfe12-df21-423f-bed8-f59b07070cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(mnist_train_images, num_cols = 8, num_rows = 2, cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c9cb63-02f6-4889-8e3b-44657503db05",
   "metadata": {},
   "source": [
    "### Define VAE architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610721d4-c210-43cf-a28b-fad0af352e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = mnist_train_images.shape[1:]\n",
    "LATENT_DIM = 4\n",
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffafd54e-fa05-4aac-a1c9-2e5aa31ea3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(input_shape, latent_dim = 2, downsample = 2, filter_size = 32, kernel_size = 3, padding = 'same'): \n",
    "    input = tf.keras.layers.Input(shape = input_shape, name = 'encoder_input')\n",
    "    x = input\n",
    "    for i in range(downsample):\n",
    "        x = tf.keras.layers.Conv2D(filter_size * 2**i, kernel_size = kernel_size, padding = padding, strides = 2, use_bias = False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(latent_dim * 2)(x)\n",
    "    mu, logvar = tf.keras.layers.Lambda(lambda x: tf.split(x, 2, axis = -1))(x)\n",
    "    model = tf.keras.models.Model(inputs = input, outputs = [mu, logvar], name = 'encoder')\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b1918-84ab-4e98-802c-25f345c22f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(latent_dim = 3, upsample = 2, base_size = 7, filter_size = 32, padding = 'same', kernel_size = 3):\n",
    "    input = tf.keras.layers.Input(shape = (latent_dim,))\n",
    "    x = input\n",
    "    x = tf.keras.layers.Dense(base_size * base_size * filter_size, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Reshape([base_size, base_size, filter_size])(x)\n",
    "    for i in range(upsample, 0, -1):\n",
    "        x = tf.keras.layers.Conv2DTranspose(filter_size * i, kernel_size = kernel_size, padding = padding, strides = 2, use_bias = False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(1, kernel_size = kernel_size, padding = padding, strides = 1)(x)\n",
    "    model = tf.keras.models.Model(inputs = input, outputs = x,  name = 'decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a1646-8cd2-4ed2-811a-35459123765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = build_encoder(INPUT_SHAPE, LATENT_DIM)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383bed7-b684-4a97-a326-be6078e71317",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_decoder(LATENT_DIM)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630a051-4691-40d7-ba7e-5478dfecd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEncoder(tf.keras.models.Model):\n",
    "    def __init__(self, input_shape, latent_dim, encoder_params = {}, decoder_params = {}, apply_sigmoid = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = input_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        assert 'input_shape' not in encoder_params, 'input_shape must not be part of encoder params'\n",
    "        assert 'latent_dim' not in encoder_params, 'latent_dim must not be part of encoder params'\n",
    "        self.encoder = build_encoder(self.input_dim, self.latent_dim, **encoder_params)\n",
    "        self.decoder = build_decoder(self.latent_dim, **decoder_params)\n",
    "        self.apply_sigmoid = apply_sigmoid\n",
    "\n",
    "    def encode(self, inputs):\n",
    "        mu, logvar = self.encoder(inputs)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=tf.shape(mu))\n",
    "        return mu + tf.exp(logvar * 0.5) * eps\n",
    "\n",
    "    def decode(self, inputs, apply_sigmoid = False):\n",
    "        out = self.decoder(inputs)\n",
    "        if apply_sigmoid or self.apply_sigmoid:\n",
    "            out = tf.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mu, logvar = self.encode(inputs)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.decode(z)\n",
    "        # return x, [mu, logvar]\n",
    "        return ({'reconstruction' : x}, {'latent' : [mu, logvar]})\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self,  eps = None, num_samples = 20):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(num_samples, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3aee5-7b1e-4db2-af62-45af2697a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence():\n",
    "    def inner_func(y_true, y_pred):\n",
    "        return 0.5 * tf.reduce_sum(tf.exp(y_pred[1]) + tf.square(y_pred[0]) - 1 - y_pred[1])\n",
    "    return inner_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb536d-9200-4fbb-a442-3b1c0a2ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = VAEncoder(INPUT_SHAPE, LATENT_DIM, apply_sigmoid = True)\n",
    "vae_model.build([None] + list(INPUT_SHAPE))\n",
    "vae_model.compile(\n",
    "    loss = (\n",
    "        {'reconstruction': tf.keras.losses.BinaryCrossentropy(from_logits = False, reduction = 'sum')},\n",
    "        {'latent': kl_divergence()}\n",
    "    ),\n",
    "    loss_weights = ({'reconstruction': 1}, {'latent': 3}),\n",
    "    metrics = ({'reconstruction' : ['mae']}, {'latent': [None, None]}),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c210984-5e2e-40c6-8eab-b85c33b72ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae_model.fit(mnist_train_images, mnist_train_y, validation_data = (mnist_val_images, mnist_val_y), epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef966e41-98c9-4eeb-baf0-34bce1f09feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['output_2_1_loss'])\n",
    "plt.plot(history.history['val_output_2_1_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224db7a-fb84-43b7-bea9-cd845323d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot_samples(model, hard_sigmoid = 0):\n",
    "    np.random.shuffle(mnist_val_images)\n",
    "    arr = mnist_val_images[:20]\n",
    "    mu, logvar = model.encode(arr)\n",
    "    z = model.reparameterize(mu, logvar)\n",
    "    samples = model.sample(eps = z).numpy()\n",
    "    if hard_sigmoid:\n",
    "        samples = np.where(samples <= hard_sigmoid, 0, 1)\n",
    "    plot_samples(arr, num_cols = 10, num_rows = 2, cmap = 'Greys_r', shuffle = False, title = 'Original Images')\n",
    "    plot_samples(samples, num_cols = 10, num_rows = 2, cmap = 'Greys_r', shuffle = False, title = 'Generated Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f47b3-f920-42a0-9e4b-415c0bda6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_plot_samples(vae_model, hard_sigmoid = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad911eb8-ef0d-465e-8a12-da2ee40841bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = vae_model.sample(num_samples = 30).numpy()\n",
    "samples = np.where(samples <= 0.5, 0, 1)\n",
    "plot_samples(samples, num_cols = 10, num_rows = 3, cmap = 'Greys_r', title = 'Sampled Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30144827-dcc9-41f9-8edc-e6b70a9a3c13",
   "metadata": {},
   "source": [
    "## 02 - Gaussian VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97979ad3-7c1f-4c3d-8059-f43dee1fc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 2, use the cartoons dataset for this instead. \n",
    "# to demonstrate gaussian output\n",
    "# in another notebook to do gaussian covariate prior \n",
    "# to show that there is a spatial relationship to pixels really and pixels that are one level apart can be related"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
